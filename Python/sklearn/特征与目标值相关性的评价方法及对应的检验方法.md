## sklearn与特征筛选

`sklearn.feature_selection`子模块顾名思义, 是对特征进行选择, 也就是特征筛选的模块. 常用的方法根据具体的情况分为:

- 分类任务
  - 该特征是**二值特征**或**类别特征**:
    - `chi2`
  - 该特征是**数值型特征**, 包括连续特征和离散特征, 只要值的大小有意义即可
    - `f_classif`
  - 任何类型的特征, 需要注明特征的类型
    - `mutual_info_classif`
- 回归任务
  - 特征是**数值型特征**, 包括连续特征和离散特征, 只要值的大小有意义即可
    - `f_regression`
  - 任何类型的特征, 需要注明特征的类型
    - `mutual_info_regression`

## 基于检验方法的特征筛选

这类方法都是基于统计学的检验方法: `chi2`, `f_classif`, `f_regression`. 分别说明.

### chi2

**`chi2(X, y)`**

首先要求目标`y`是分类标签, 然后要求进行检验的特征必须是**二值特征**, 即特征值非0即1. 因为`chi2`是通过**卡方检验**来不同的目标标签对应的特征表现是否相同, 从而说明该特征对目标标签的区分能力强不强. 如果目标标签的每类中对应特征的**期望频数**和**观测频数**接近, 说明没有区别能力, 这个特征可能不能起到很好的作用. 具体的原理参考[0x01 分类数据分析基础](Math/概率论/统计推断/0x04 分类数据分析/0x01 分类数据分析基础.md).

如果一个特征是**类别**特征, 则需要通过`One-Hot`进行编码后使用.
