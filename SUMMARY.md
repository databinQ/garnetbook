* [MATH](MATH)
  - [EM](Math/EM)
    - [0x01 基础知识准备](Math/EM/0x01 基础知识准备.md)
    - [0x02 期望最大化算法](Math/EM/0x02 期望最大化算法.md)
  - [MCMC](Math/MCMC)
    - [0x01 蒙特卡罗与马尔科夫链](Math/MCMC/0x01 蒙特卡罗与马尔科夫链.md)
    - [0x02 采样实例](Math/MCMC/0x02 采样实例.md)
    - [0x03 PyMC与MCMC](Math/MCMC/0x03 PyMC与MCMC.md)
  - [概率论](Math/概率论)
    - [分布](Math/概率论/分布)
    - [统计推断](Math/概率论/统计推断)
* [时间序列](时间序列)
    - [0x01 时间序列概念](时间序列/0x01-时间序列概念.md)
    - [0x02 ARIMA模型](时间序列/0x02-ARIMA模型.md)
    - [0x03 ACF与PACF](时间序列/0x03-ACF与PACF.md)
    - [0x04 拟合度量方法](时间序列/0x04-拟合度量方法.md)
    - [0x05 时间序列中的检验](时间序列/0x05-时间序列中的检验.md)
    - [0x06 简单的时间序列建模例子](时间序列/0x06-简单的时间序列建模例子.md)
    - [0x07 季节性](时间序列/0x07-季节性.md)
    - [0x08 SARIMAX](时间序列/0x08-SARIMAX.md)
    - [0x09 完整的时间序列SARIMAX建模思路及例子](时间序列/0x09-完整的时间序列SARIMAX建模思路及例子.md)
* [自然语言处理](自然语言处理)
  - [Embeddings](自然语言处理/Embeddings)
    - [Embedding原理](自然语言处理/Embeddings/Embedding原理.md)
    - [word2vec](自然语言处理/Embeddings/word2vec)
        - [0x01 word2vec算法原理](自然语言处理/Embeddings/word2vec/0x01-word2vec算法原理.md)
        - [0x02 Hierarchical Softmax](自然语言处理/Embeddings/word2vec/0x02-Hierarchical Softmax.md)
        - [0x03 Negative Sampling](自然语言处理/Embeddings/word2vec/0x03-Negative Sampling.md)
    - [GloVe](自然语言处理/Embeddings/GloVe)
        - [GloVe原理](自然语言处理/Embeddings/GloVe/GloVe原理.md)
    - [其他Embedding方法](自然语言处理/Embeddings/其他Embedding方法.md)
  - [句子相似性](自然语言处理/句子相似性)
    - [句子相似性求解总结](自然语言处理/句子相似性/句子相似性求解总结.md)
    - [论文阅读 A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SEN- TENCE EMBEDDINGS](自然语言处理/句子相似性/论文阅读 A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SEN- TENCE EMBEDDINGS)
  - [模型结构](自然语言处理/模型结构)
    - [DIIN](自然语言处理/模型结构/DIIN)
      - [DIIN论文笔记](自然语言处理/模型结构/DIIN/DIIN论文笔记.md)
  - [主题模型](自然语言处理/主题模型)
    - [LSA](自然语言处理/主题模型/LSA)
      - [0x01 LSA](自然语言处理/主题模型/LSA/0x01 LSA.md)
      - [0x02 PLSA](自然语言处理/主题模型/LSA/0x02 PLSA.md)
    - [LDA](自然语言处理/主题模型/LDA)
      - [LDA](自然语言处理/主题模型/LDA/LDA.md)
  - [NLP常见任务](自然语言处理/NLP常见任务.md)
* [LATEX公式备忘](LATEX公式备忘.md)
